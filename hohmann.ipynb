{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the action space and observation space of the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-0.1, 0.1, (1,), float32)\n",
      "Box(-inf, inf, (3,), float32)\n"
     ]
    }
   ],
   "source": [
    "from HohmannTransferEnv import HohmannTransferEnv\n",
    "\n",
    "env = HohmannTransferEnv()\n",
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the step function of the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:  [-0.07227103]\n",
      "Next state:  [array([-0.00036136, -0.00036136]) array([-0.0072271, -0.0072271])\n",
      " 1.5262548949600395e+24] Reward:  1 Done:  False\n",
      "Action:  [-0.09879111]\n",
      "Next state:  [array([7.63127425e+18, 7.63127425e+18])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 3.422168615646904e-21] Reward:  1 Done:  False\n",
      "Action:  [0.08435822]\n",
      "Next state:  [array([2.28938239e+19, 2.28938239e+19])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 3.802409207707702e-22] Reward:  1 Done:  False\n",
      "Action:  [-0.0181253]\n",
      "Next state:  [array([3.81563735e+19, 3.81563735e+19])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.368867288477977e-22] Reward:  1 Done:  False\n",
      "Action:  [0.02488953]\n",
      "Next state:  [array([5.34189231e+19, 5.34189231e+19])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 6.984016720448583e-23] Reward:  1 Done:  False\n",
      "Action:  [0.05876366]\n",
      "Next state:  [array([6.86814727e+19, 6.86814727e+19])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 4.2248989844036456e-23] Reward:  1 Done:  False\n",
      "Action:  [0.04424293]\n",
      "Next state:  [array([8.39440223e+19, 8.39440223e+19])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.8282381548810293e-23] Reward:  1 Done:  False\n",
      "Action:  [-0.00402405]\n",
      "Next state:  [array([9.92065719e+19, 9.92065719e+19])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.0249515742662916e-23] Reward:  1 Done:  False\n",
      "Action:  [-0.02792253]\n",
      "Next state:  [array([1.14469121e+20, 1.14469121e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.5209636246457584e-23] Reward:  1 Done:  False\n",
      "Action:  [-0.02430234]\n",
      "Next state:  [array([1.29731671e+20, 1.29731671e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.1841412289224156e-23] Reward:  1 Done:  False\n",
      "Action:  [0.06242358]\n",
      "Next state:  [array([1.44994221e+20, 1.44994221e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 9.479690162140577e-24] Reward:  1 Done:  False\n",
      "Action:  [0.09760046]\n",
      "Next state:  [array([1.6025677e+20, 1.6025677e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 7.760018471794205e-24] Reward:  1 Done:  False\n",
      "Action:  [0.01323686]\n",
      "Next state:  [array([1.7551932e+20, 1.7551932e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 6.469126926312983e-24] Reward:  1 Done:  False\n",
      "Action:  [0.08075428]\n",
      "Next state:  [array([1.90781869e+20, 1.90781869e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 5.475469027687296e-24] Reward:  1 Done:  False\n",
      "Action:  [-0.0680556]\n",
      "Next state:  [array([2.06044419e+20, 2.06044419e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 4.694332154792355e-24] Reward:  1 Done:  False\n",
      "Action:  [0.0890297]\n",
      "Next state:  [array([2.21306969e+20, 2.21306969e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 4.069165445403332e-24] Reward:  1 Done:  False\n",
      "Action:  [-0.03473765]\n",
      "Next state:  [array([2.36569518e+20, 2.36569518e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 3.561049051495612e-24] Reward:  1 Done:  False\n",
      "Action:  [0.01722962]\n",
      "Next state:  [array([2.51832068e+20, 2.51832068e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 3.1424868113161843e-24] Reward:  1 Done:  False\n",
      "Action:  [-0.06201299]\n",
      "Next state:  [array([2.67094618e+20, 2.67094618e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.7936066421792095e-24] Reward:  1 Done:  False\n",
      "Action:  [-0.03359754]\n",
      "Next state:  [array([2.82357167e+20, 2.82357167e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.499757586492361e-24] Reward:  1 Done:  False\n",
      "Action:  [-0.02490687]\n",
      "Next state:  [array([2.97619717e+20, 2.97619717e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.2499461770050315e-24] Reward:  1 Done:  False\n",
      "Action:  [-0.02694532]\n",
      "Next state:  [array([3.12882266e+20, 3.12882266e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.0357930604449354e-24] Reward:  1 Done:  False\n",
      "Action:  [-0.00736684]\n",
      "Next state:  [array([3.28144816e+20, 3.28144816e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.8508210568137314e-24] Reward:  1 Done:  False\n",
      "Action:  [-0.05407215]\n",
      "Next state:  [array([3.43407366e+20, 3.43407366e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.689959572118006e-24] Reward:  1 Done:  False\n",
      "Action:  [-0.0048083]\n",
      "Next state:  [array([3.58669915e+20, 3.58669915e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.5491933603769608e-24] Reward:  1 Done:  False\n",
      "Action:  [-0.08899707]\n",
      "Next state:  [array([3.73932465e+20, 3.73932465e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.4253095096395306e-24] Reward:  1 Done:  False\n",
      "Action:  [-0.02903415]\n",
      "Next state:  [array([3.89195014e+20, 3.89195014e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.315712469146445e-24] Reward:  1 Done:  False\n",
      "Action:  [0.05165893]\n",
      "Next state:  [array([4.04457564e+20, 4.04457564e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.2182869818031596e-24] Reward:  1 Done:  False\n",
      "Action:  [-0.00388434]\n",
      "Next state:  [array([4.19720114e+20, 4.19720114e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.1312952500981093e-24] Reward:  1 Done:  False\n",
      "Action:  [-0.07997394]\n",
      "Next state:  [array([4.34982663e+20, 4.34982663e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.0532989015796323e-24] Reward:  1 Done:  False\n",
      "Action:  [0.093028]\n",
      "Next state:  [array([4.50245213e+20, 4.50245213e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 9.830991470666463e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.00014913]\n",
      "Next state:  [array([4.65507762e+20, 4.65507762e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 9.196904409204504e-25] Reward:  1 Done:  False\n",
      "Action:  [0.09364231]\n",
      "Next state:  [array([4.80770312e+20, 4.80770312e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 8.62224270700023e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.02659467]\n",
      "Next state:  [array([4.96032862e+20, 4.96032862e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 8.099806225248705e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.07419794]\n",
      "Next state:  [array([5.11295411e+20, 5.11295411e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 7.623453174295258e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.03337771]\n",
      "Next state:  [array([5.26557961e+20, 5.26557961e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 7.1879187769960775e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.04649773]\n",
      "Next state:  [array([5.4182051e+20, 5.4182051e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 6.7886691718439595e-25] Reward:  1 Done:  False\n",
      "Action:  [0.07362239]\n",
      "Next state:  [array([5.5708306e+20, 5.5708306e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 6.421782941145201e-25] Reward:  1 Done:  False\n",
      "Action:  [0.05799003]\n",
      "Next state:  [array([5.7234561e+20, 5.7234561e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 6.083854451833179e-25] Reward:  1 Done:  False\n",
      "Action:  [0.0277233]\n",
      "Next state:  [array([5.87608159e+20, 5.87608159e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 5.771914536996803e-25] Reward:  1 Done:  False\n",
      "Action:  [0.0833977]\n",
      "Next state:  [array([6.02870709e+20, 6.02870709e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 5.483365051791847e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.07346404]\n",
      "Next state:  [array([6.18133258e+20, 6.18133258e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 5.215924597880178e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.04554865]\n",
      "Next state:  [array([6.33395808e+20, 6.33395808e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 4.967583290060248e-25] Reward:  1 Done:  False\n",
      "Action:  [0.02193249]\n",
      "Next state:  [array([6.48658358e+20, 6.48658358e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 4.736564883574709e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.08372002]\n",
      "Next state:  [array([6.63920907e+20, 6.63920907e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 4.521294924361707e-25] Reward:  1 Done:  False\n",
      "Action:  [0.02619654]\n",
      "Next state:  [array([6.79183457e+20, 6.79183457e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 4.320373851940436e-25] Reward:  1 Done:  False\n",
      "Action:  [0.08397951]\n",
      "Next state:  [array([6.94446006e+20, 6.94446006e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 4.132554193938244e-25] Reward:  1 Done:  False\n",
      "Action:  [0.06185213]\n",
      "Next state:  [array([7.09708556e+20, 7.09708556e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 3.956721156068605e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.09564193]\n",
      "Next state:  [array([7.24971106e+20, 7.24971106e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 3.791876041852766e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.07199075]\n",
      "Next state:  [array([7.40233655e+20, 7.40233655e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 3.637122040243498e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.03438425]\n",
      "Next state:  [array([7.55496205e+20, 7.55496205e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 3.491652002410384e-25] Reward:  1 Done:  False\n",
      "Action:  [0.07929974]\n",
      "Next state:  [array([7.70758754e+20, 7.70758754e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 3.354737895759038e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.04267462]\n",
      "Next state:  [array([7.86021304e+20, 7.86021304e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 3.2257216772259423e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.00722566]\n",
      "Next state:  [array([8.01283854e+20, 8.01283854e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 3.1040073716805625e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.01470786]\n",
      "Next state:  [array([8.16546403e+20, 8.16546403e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.989054176949993e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.04539319]\n",
      "Next state:  [array([8.31808953e+20, 8.31808953e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.88037044617919e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.01976447]\n",
      "Next state:  [array([8.47071502e+20, 8.47071502e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.7775084222254602e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.08518173]\n",
      "Next state:  [array([8.62334052e+20, 8.62334052e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.6800596185647826e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.01374815]\n",
      "Next state:  [array([8.77596602e+20, 8.77596602e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.587650757557267e-25] Reward:  1 Done:  False\n",
      "Action:  [0.045589]\n",
      "Next state:  [array([8.92859151e+20, 8.92859151e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.499940190515154e-25] Reward:  1 Done:  False\n",
      "Action:  [0.07287904]\n",
      "Next state:  [array([9.08121701e+20, 9.08121701e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.416614735347339e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.08786301]\n",
      "Next state:  [array([9.2338425e+20, 9.2338425e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.3373868770281265e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.03801778]\n",
      "Next state:  [array([9.386468e+20, 9.386468e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.26199228408396e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.09784938]\n",
      "Next state:  [array([9.5390935e+20, 9.5390935e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.1901876009769486e-25] Reward:  1 Done:  False\n",
      "Action:  [0.02367293]\n",
      "Next state:  [array([9.69171899e+20, 9.69171899e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.1217484819048697e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.08898101]\n",
      "Next state:  [array([9.84434449e+20, 9.84434449e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 2.056467836310422e-25] Reward:  1 Done:  False\n",
      "Action:  [0.03829712]\n",
      "Next state:  [array([9.99696998e+20, 9.99696998e+20])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.9941542604427586e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.08011723]\n",
      "Next state:  [array([1.01495955e+21, 1.01495955e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.934630632760031e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.04322682]\n",
      "Next state:  [array([1.0302221e+21, 1.0302221e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.8777328539008487e-25] Reward:  1 Done:  False\n",
      "Action:  [0.02208507]\n",
      "Next state:  [array([1.04548465e+21, 1.04548465e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.8233087144658626e-25] Reward:  1 Done:  False\n",
      "Action:  [0.03744514]\n",
      "Next state:  [array([1.0607472e+21, 1.0607472e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.7712168760049652e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.09742294]\n",
      "Next state:  [array([1.07600975e+21, 1.07600975e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.7213259524565559e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.08024282]\n",
      "Next state:  [array([1.0912723e+21, 1.0912723e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.6735136808792461e-25] Reward:  1 Done:  False\n",
      "Action:  [0.05677142]\n",
      "Next state:  [array([1.10653485e+21, 1.10653485e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.6276661716919914e-25] Reward:  1 Done:  False\n",
      "Action:  [0.032924]\n",
      "Next state:  [array([1.1217974e+21, 1.1217974e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.5836772298283804e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.05351557]\n",
      "Next state:  [array([1.13705994e+21, 1.13705994e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.541447739241982e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.09493919]\n",
      "Next state:  [array([1.15232249e+21, 1.15232249e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.5008851040951253e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.05664378]\n",
      "Next state:  [array([1.16758504e+21, 1.16758504e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.4619027407427104e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.0074035]\n",
      "Next state:  [array([1.18284759e+21, 1.18284759e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.4244196153019883e-25] Reward:  1 Done:  False\n",
      "Action:  [0.0605245]\n",
      "Next state:  [array([1.19811014e+21, 1.19811014e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.388359822192586e-25] Reward:  1 Done:  False\n",
      "Action:  [0.00979072]\n",
      "Next state:  [array([1.21337269e+21, 1.21337269e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.3536521995502558e-25] Reward:  1 Done:  False\n",
      "Action:  [0.03556727]\n",
      "Next state:  [array([1.22863524e+21, 1.22863524e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.320229977872952e-25] Reward:  1 Done:  False\n",
      "Action:  [0.04848368]\n",
      "Next state:  [array([1.24389779e+21, 1.24389779e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.288030458657421e-25] Reward:  1 Done:  False\n",
      "Action:  [0.00714146]\n",
      "Next state:  [array([1.25916034e+21, 1.25916034e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.2569947201359913e-25] Reward:  1 Done:  False\n",
      "Action:  [0.06862924]\n",
      "Next state:  [array([1.27442289e+21, 1.27442289e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.22706734753288e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.03107623]\n",
      "Next state:  [array([1.28968544e+21, 1.28968544e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.1981961855325472e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.01524777]\n",
      "Next state:  [array([1.30494799e+21, 1.30494799e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.1703321108940819e-25] Reward:  1 Done:  False\n",
      "Action:  [0.01530021]\n",
      "Next state:  [array([1.32021054e+21, 1.32021054e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.1434288233593002e-25] Reward:  1 Done:  False\n",
      "Action:  [0.08426431]\n",
      "Next state:  [array([1.33547309e+21, 1.33547309e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.117442653191666e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.0721395]\n",
      "Next state:  [array([1.35073564e+21, 1.35073564e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.092332383851269e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.07135783]\n",
      "Next state:  [array([1.36599819e+21, 1.36599819e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.0680590884605716e-25] Reward:  1 Done:  False\n",
      "Action:  [0.02564195]\n",
      "Next state:  [array([1.38126074e+21, 1.38126074e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.044585978848655e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.04483399]\n",
      "Next state:  [array([1.39652329e+21, 1.39652329e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 1.0218782660802975e-25] Reward:  1 Done:  False\n",
      "Action:  [-0.03513602]\n",
      "Next state:  [array([1.41178584e+21, 1.41178584e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 9.999030314820102e-26] Reward:  1 Done:  False\n",
      "Action:  [-0.05274808]\n",
      "Next state:  [array([1.42704839e+21, 1.42704839e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 9.786291072717764e-26] Reward:  1 Done:  False\n",
      "Action:  [0.03198263]\n",
      "Next state:  [array([1.44231094e+21, 1.44231094e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 9.580269659838114e-26] Reward:  1 Done:  False\n",
      "Action:  [-0.05309699]\n",
      "Next state:  [array([1.45757349e+21, 1.45757349e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 9.38068617955499e-26] Reward:  1 Done:  False\n",
      "Action:  [0.02514534]\n",
      "Next state:  [array([1.47283604e+21, 1.47283604e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 9.187275162116313e-26] Reward:  1 Done:  False\n",
      "Action:  [-0.0298038]\n",
      "Next state:  [array([1.48809859e+21, 1.48809859e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 8.999784681421439e-26] Reward:  1 Done:  False\n",
      "Action:  [0.01579676]\n",
      "Next state:  [array([1.50336114e+21, 1.50336114e+21])\n",
      " array([1.52625496e+20, 1.52625496e+20]) 8.817975534244202e-26] Reward:  1 Done:  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielgeorge/Documents/work/bio/embeddings/hohmann-transfer-rl/HohmannTransferEnv.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.state = np.array([pos_, vel_, Fg_])\n"
     ]
    }
   ],
   "source": [
    "env = HohmannTransferEnv()\n",
    "env.reset()\n",
    "for _ in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    print(\"Action: \", action)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    print(\"Next state: \", next_state, \"Reward: \", reward, \"Done: \", done)\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't really understand how the step function works. \n",
    "Let's think step by step what we're trying to do and what we need to do it.\n",
    "- We're at a certain state\n",
    "  - This includes\n",
    "    - position and velocity of the spacecraft in both x and y directions\n",
    "    - gravitational force\n",
    "- We have 2 actions available to us\n",
    "  - thrust in x direction\n",
    "  - thrust in y direction\n",
    "- We want to get to the next state\n",
    "  - We need to calculate the new position and velocity of the spacecraft\n",
    "    - We need to know if we've crashed\n",
    "      - I don't see a definition of where the earth is and how big it is in the environment\n",
    "        - We need to add the following constraints:\n",
    "          - The radius of the earth will be 10 units and it will be positioned at the origin (we might need to decrease maximum thrust). If the rocket enters this region or is more than 100 units away from the origin, the environment terminates.\n",
    "- Let's say that we're at a state \n",
    "- We need to solve an ODE to get to the next state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state of the system includes the position and velocity of the spacecraft in both the x and y directions, and the gravitational force acting on the spacecraft. The actions you have available are thrusts in the x and y directions.\n",
    "\n",
    "Now, how do you get from one state to the next given a certain action? This is defined by the dynamics of the system, which in this case are given by the differential equation:\n",
    "$$\\ddot{\\mathbf{x}} = \\frac{G M_E}{|\\mathbf{x}|^3}\\mathbf{x} + a$$\n",
    "\n",
    "Here:\n",
    "\n",
    "$\\ddot{\\mathbf{x}}$ is the second derivative of the position vector, which represents the acceleration of the spacecraft.\n",
    "$G$ is the gravitational constant, $M_E$ is the mass of the Earth, and $|\\mathbf{x}|$ is the distance from the spacecraft to the center of the Earth.\n",
    "$\\mathbf{x}$ is the position vector of the spacecraft.\n",
    "$a$ is the acceleration due to the thrust of the spacecraft.\n",
    "The left-hand side of the equation represents the total acceleration of the spacecraft, and the right-hand side represents the forces acting on the spacecraft (gravity and thrust), divided by the mass of the spacecraft to get acceleration (from F=ma).\n",
    "\n",
    "This is a second-order differential equation because it involves the second derivative of the position. Most numerical solvers, like the solve_ivp function from SciPy, can only solve first-order differential equations. Therefore, we need to convert this second-order equation into a system of first-order equations.\n",
    "\n",
    "This is done by introducing new variables: $\\mathbf{y}_1$ represents the position, $\\mathbf{y}_2$ represents the velocity, and $\\mathbf{y}_3$ represents the acceleration. Now, we have three first-order differential equations:\n",
    "\n",
    "$\\mathbf{y}_1 = \\mathbf{x}$: The position.\n",
    "\n",
    "$\\mathbf{y}_2 = \\dot{\\mathbf{y}}_1$: The rate of change of position is the velocity.\n",
    "\n",
    "$\\mathbf{y}_3 = \\frac{G M_E}{|\\mathbf{y}_1|^3}\\mathbf{y}_1 + a$: This is the original differential equation, but written in terms of $\\mathbf{y}_1$ instead of $\\mathbf{x}$.\n",
    "\n",
    "Given the current state of the system (the position, velocity, and gravitational force), and a certain action (the thrust), you can solve these differential equations over a short time interval to find the state of the system at the next time step.\n",
    "\n",
    "To check if the spacecraft has crashed, you calculate the distance from the spacecraft to the center of the Earth (which is at the origin of your coordinate system) and check if it's less than the radius of the Earth (10 units in your case), or if it's more than 100 units away.\n",
    "\n",
    "Here is a step-by-step example:\n",
    "\n",
    "Let's say the spacecraft is initially at position (x, y) = (15, 0) with velocity (vx, vy) = (0, 1) and the gravitational force Fg is 0.02. So your state is [15, 0, 0, 1, 0.02].\n",
    "\n",
    "The action chosen by the agent is to thrust with (ax, ay) = (0.05, 0). This is the acceleration due to thrust.\n",
    "\n",
    "Define the system of first-order ODEs as explained above.\n",
    "\n",
    "Use solve_ivp to solve these ODEs over a 1-second interval. The output of solve_ivp gives you the state of the system at the next time step.\n",
    "\n",
    "Check if the new position of the spacecraft is within the Earth's radius or more than 100 units away. If it is, the episode is done.\n",
    "\n",
    "Repeat steps 2-5 for the next action until the episode is done.\n",
    "\n",
    "In your current code, you have already implemented these steps in the step function. However, the differential equation in your ode function might be slightly incorrect, it should be:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
